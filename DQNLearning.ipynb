{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    !git clone https://github.com/MalahitTV/RL-single-pong.git\n",
    "except:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from importlib import reload\n",
    "import game2\n",
    "import dqn_agent\n",
    "game2 = reload(game2)\n",
    "dqn_agent = reload(dqn_agent)\n",
    "from game2 import Game\n",
    "from dqn_agent import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "moving_average = lambda x, **kw: pd.DataFrame({'x':np.asarray(x)}).x.ewm(**kw).mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Flattener(nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size, *_ = x.shape\n",
    "        return x.reshape(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, in_channels, out_size, h=210, w=160):\n",
    "      super(Policy, self).__init__()\n",
    "      def conv2d_size_out(size, kernel_size = 4, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "      \n",
    "      self.h = h\n",
    "      self.w = w\n",
    "      \n",
    "      convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w, 8, 4)), 3, 1)\n",
    "      convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h, 8, 4)), 3, 1)\n",
    "      linear_input = convh * convw * 64\n",
    "      self.act = nn.Sequential(nn.Conv2d(in_channels, 32, kernel_size=8, stride=4),\n",
    "                               nn.BatchNorm2d(32),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "                               nn.BatchNorm2d(64),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "                               nn.BatchNorm2d(64),\n",
    "                               nn.ReLU(),\n",
    "                               Flattener(),\n",
    "                               nn.Linear(linear_input, 1000),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(1000, out_size)\n",
    "                               )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if len(X.shape) < 4:\n",
    "            X = X.view(1, X.shape[0], X.shape[1], X.shape[2])\n",
    "        return self.act(X)\n",
    "    \n",
    "    # def get_parameters(self):\n",
    "    #    return self.state_dict()\n",
    "    # \n",
    "    # def set_parameters(self, state_dict):\n",
    "    #     self.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "in_channels = 3\n",
    "out_size = 3\n",
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                transforms.Resize(size=(84, 84)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.20, 0.20, 0.20])]\n",
    "                               )\n",
    "\n",
    "model = Policy(in_channels, out_size, h=84, w=84).to(device)\n",
    "target_model = Policy(in_channels, out_size, h=84, w=84).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "dqn = DQNAgent(model, target_model, loss_func , out_size, memory=30000, n_multi_step=2, device=device,\n",
    "               double_dqn=True, transform=transform, gamma=.99, epsilon_start=1.0, epsilon_end=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "env = Game(True)\n",
    "dqn.fit(env, 500, batch_size=batch_size, optimizer=optimizer,\n",
    "        train_every=1, start_train_steps=10001,  update_model=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_agent(env, transform=None, agent=None, n_episodes=100):\n",
    "    \"\"\"Runs agent for n_episodes in environment and calclates mean reward.\n",
    "    \n",
    "    Args:\n",
    "        env: The environment for agent to play in\n",
    "        agent: The agent to play with. Defaults to None - \n",
    "            in this case random agent is used.\n",
    "        n_episodes: Number of episodes to play. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    total_reward = []\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output2.avi', fourcc, 60, (160, 210))\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        episode_reward = 0\n",
    "        observation = env.reset()\n",
    "        t = 0\n",
    "        while True:\n",
    "            if agent:\n",
    "                agent.train(False)\n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    if transform:\n",
    "                        observation = torch.as_tensor(observation, dtype=torch.uint8)\n",
    "                        observation = transform(observation)\n",
    "                    probs = agent(torch.as_tensor(observation, device=device))\n",
    "                    action = torch.argmax(F.softmax(probs, dim=-1)).item()\n",
    "            else:\n",
    "                action = random.randint(0, 2)\n",
    "            observation, reward, done, state  = env.step(action)\n",
    "            out.write(observation)\n",
    "            episode_reward += reward\n",
    "            t += 1\n",
    "            if done:\n",
    "                print(\"Episode {} finished after {} timesteps\".format(episode+1, t+1))\n",
    "                break\n",
    "        total_reward.append(episode_reward)\n",
    "    env.stop()\n",
    "    out.release()  \n",
    "    # cv2.destroyAllWindows()\n",
    "    return np.mean(total_reward) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = torch.load('model.mod')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = Game(True)\n",
    "test_agent(env, transform, agent=model, n_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}